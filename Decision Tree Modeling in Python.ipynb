{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGWafgBdEuCg"
      },
      "outputs": [],
      "source": [
        "## Decision Tree Modeling in Python\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import metrics\n",
        "np.random.seed(66)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset and preprocessing: The dataset includes 21 varibales and one target feature (Churn?).\n",
        "#Decision Tree Induction needs numeric values, therefore columns with object types were either coverted or dropped.\n",
        "churn = pd.read_csv('https://raw.githubusercontent.com/yhat/demo-churn-pred/master/model/churn.csv')\n",
        "churn.columns\n",
        "churn[\"Int'l Plan\"] = churn[\"Int'l Plan\"].map(dict(yes=1, no=0))\n",
        "churn['VMail Plan'] = churn['VMail Plan'].replace({\"yes\": 1, \"no\": 0})\n",
        "churn.select_dtypes('object').columns\n",
        "\n",
        "# sklearn expect all numerical attributes\n",
        "churn.drop(['State', 'Phone'], inplace=True, axis=1)\n",
        "churn.head()"
      ],
      "metadata": {
        "id": "QIru-9xCE5Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training: Dropped the target feature from the X dataset and keep the rest of the dataset for testing. For the y dataset, keep only the target feature for prediction.\n",
        "## Split the X and y dataset into tranining (70%) and testing (30%) and setting a random seed of 1\n",
        "X = churn.drop('Churn?', axis=1)\n",
        "y = churn['Churn?']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "print(f\"train data size is {X_train.shape}\")\n",
        "\n",
        "#Create decision tree classifier function\n",
        "clf = DecisionTreeClassifier()\n",
        "clf"
      ],
      "metadata": {
        "id": "JxvI2c31E5tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data information for the X training dataset with all varibales having a numeric datatype\n",
        "X_train.info()"
      ],
      "metadata": {
        "id": "nbVe_4wWy931"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Hyperparamter Fine Tuning:\n",
        "#Criterion is used to split the decision tree to gain information\n",
        "#min_samples_split: minimum # of samples to split at internal node\n",
        "#max_depth: maximum depth of the decision tree\n",
        "#min_samples_leaf: minimum # of samples att leaf node\n",
        "#max_leaf_nodes: maximum number of leaf nodes in decision tree\n",
        "\n",
        "\n",
        "param_grid = {'criterion': ['gini', 'entropy'],\n",
        "              'min_samples_split': [2,10,20],\n",
        "              'max_depth': [5,10,20,25,30],\n",
        "              'min_samples_leaf': [1,5,10],\n",
        "              'max_leaf_nodes': [2,5,10,20]}\n",
        "\n",
        "#GridSearchCV: Searching the paramter grid to find the best hypermeters to crosss-validate the model performance\n",
        "#cv: cross-validation by dividing the dataset into equal parts to train and evaluate it\n",
        "#Accuarcy for model perofrmance metric\n",
        "grid = GridSearchCV(clf, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "#Using the grid to fit the training dataset to iterates through the hyperparamters set above\n",
        "grid.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "TRGVRMg-zX3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Output Best Model Hyperparameters\n",
        "# Entropy evaluated the quality of the model with an accuracy score of 0.94\n",
        "\n",
        "print(grid.best_score_)\n",
        "for hps, values in grid.best_params_.items():\n",
        "  print(f\"{hps}: {values}\")"
      ],
      "metadata": {
        "id": "eZhW6pRd0qat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: There are over 80% of False compared to true\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16, 8))\n",
        "churn['Churn?'].value_counts(normalize=True).plot.bar(rot=45);\n",
        "plt.xlabel(\"Churn Status\")\n",
        "plt.ylabel(\"Distribution\")"
      ],
      "metadata": {
        "id": "jxZAcf--1aY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}