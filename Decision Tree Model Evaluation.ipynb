{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHsWX2yk2jQ8"
      },
      "outputs": [],
      "source": [
        "## Decision Tree Modeling in Python\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate, ShuffleSplit, LeaveOneOut\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "np.random.seed(66)\n",
        "\n",
        "churn = pd.read_csv('https://raw.githubusercontent.com/yhat/demo-churn-pred/master/model/churn.csv')\n",
        "churn[\"Int'l Plan\"] = churn[\"Int'l Plan\"].map(dict(yes=1, no=0))\n",
        "churn['VMail Plan'] = churn['VMail Plan'].replace({\"yes\": 1, \"no\": 0})\n",
        "churn.select_dtypes('object').columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training/Testing\n",
        "\n",
        "num_vars = churn.select_dtypes('number').columns\n",
        "X = churn[num_vars]\n",
        "y = churn['Churn?'].map({'True.': 1, 'False.': 0})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=16)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "plt.hist(y_pred, bins=2)\n",
        "plt.xticks(range(0, 2))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mGEzfVEP3zmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Performance Reporting\n",
        "\n",
        "print(f\"Accuracy: {round(metrics.accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
        "df_confusion = pd.crosstab(y_test, y_pred)\n",
        "df_confusion.index = [['Real', 'Real'], ['Stay', 'Leave']]\n",
        "df_confusion.columns = [['Predict'] * 2, ['Stay', 'Leave']]\n",
        "df_confusion\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "KNThJFco3zte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameters' Grid Search\n",
        "\n",
        "param_grid = {'criterion': ['gini', 'entropy'],\n",
        "              'min_samples_split': [2, 10, 20, 30],\n",
        "              'max_depth': [4, 5, 6, 10, 15, 20],\n",
        "              'min_samples_leaf': [ 1, 5, 10],\n",
        "              'max_leaf_nodes': [2, 5, 10, 20]}\n",
        "grid = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid)"
      ],
      "metadata": {
        "id": "e1jUuIx86TgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Repeated Hold-Out Method\n",
        "\n",
        "bstrap = ShuffleSplit(n_splits=10, test_size=0.3, random_state=16)\n",
        "grid_bstrap = GridSearchCV(clf, param_grid, cv=bstrap)\n",
        "grid_bstrap.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2b0dbddT3z0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameters for Best Performinig Model\n",
        "\n",
        "print(f\"Accuracy: {round(grid_bstrap.best_score_*100, 2)}%\")\n",
        "for key, value in grid_bstrap.best_params_.items():\n",
        "  print(f\"Hyperparameter: {key}; Value: {value}\")"
      ],
      "metadata": {
        "id": "QoaR7bJ_3z44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Leave One Out\n",
        "\n",
        "loocv = LeaveOneOut()\n",
        "lv_score = cross_val_score(clf, X, y, cv=loocv)\n",
        "print(f\"Leave One Out accuracy is {round(lv_score.mean(), 2)}\")"
      ],
      "metadata": {
        "id": "1vP5F80b3z8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ROC-AUC Curve\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "y_pred_prob = grid.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"AUC = {auc}\")\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "import seaborn as sns\n",
        "sns.lineplot(x=fpr, y=tpr)\n",
        "plt.xlabel('1 - Specificity')\n",
        "plt.ylabel('Sensitivity')"
      ],
      "metadata": {
        "id": "fjWsK3kn30CB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}